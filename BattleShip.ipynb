{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f03f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from tensorflow.keras.backend import clear_session #not sure if we need this but it does not hurt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce670df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly places a ship on a board\n",
    "def set_ship(ship, ships, board, ship_locs):\n",
    "\n",
    "    grid_size = board.shape[0]\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        init_pos_i = np.random.randint(0, grid_size)\n",
    "        init_pos_j = np.random.randint(0, grid_size)\n",
    "                    \n",
    "        # for a cruiser, if init_oos_i = 0, move forward horizontally (+1)\n",
    "        # for a cruiser, if init_oos_j = 0, move downward vertically (+1)\n",
    "        move_j = grid_size - init_pos_j - ships[ship]# horizontal\n",
    "        if move_j > 0:\n",
    "            move_j = 1\n",
    "        else:\n",
    "            move_j = -1\n",
    "        move_i = grid_size - init_pos_i - ships[ship] # vertical\n",
    "        if move_i > 0:\n",
    "            move_i = 1\n",
    "        else:\n",
    "            move_i = -1\n",
    "        # choose if placing ship horizontally or vertically\n",
    "        choice_hv = np.random.choice(['h', 'v']) # horizontal, vertical\n",
    "        if choice_hv == 'h': #horizontal\n",
    "            j = [(init_pos_j + move_j*jj) for jj in range(ships[ship])]\n",
    "            i = [init_pos_i for ii in range(ships[ship])]\n",
    "            pos = set(zip(i,j))     \n",
    "            if all([board[i,j]==0 for (i,j) in pos]):\n",
    "                done = True\n",
    "        elif choice_hv == 'v':\n",
    "            i = [(init_pos_i + move_i*ii) for ii in range(ships[ship])]\n",
    "            j = [init_pos_j for jj in range(ships[ship])]\n",
    "            pos = set(zip(i,j))        \n",
    "            #check if empty board in this direction\n",
    "            if all([board[i,j]==0 for (i,j) in pos]):\n",
    "                done = True\n",
    "    # set ship - see convention\n",
    "    for (i,j) in pos:\n",
    "        board[i,j] = 1\n",
    "        ship_locs[ship].append((i,j))\n",
    "    \n",
    "    return board, ship_locs\n",
    "\n",
    "def board_rendering(grid_size, board):\n",
    "    for i in range(grid_size):\n",
    "        print(\"-\"*(4*grid_size+2))\n",
    "        for j in range(grid_size):\n",
    "            current_state_value = board[i,j]\n",
    "            current_state = ('S' if current_state_value==1 else ' ')\n",
    "            print(\" | \", end=\"\")\n",
    "            print(current_state, end='')\n",
    "        print(' |')\n",
    "    print(\"-\"*(4*grid_size+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755cf530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BattleshipEnv(gym.Env):\n",
    "    \n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    \"\"\"see https://github.com/openai/gym/blob/master/gym/core.py\"\"\"\n",
    "    \n",
    "    metadata = {'render.modes': ['human']} \n",
    "\n",
    "\n",
    "    def __init__(self, enemy_board, ship_locs, grid_size, ships):\n",
    "        \n",
    "        super(BattleshipEnv, self).__init__()\n",
    "        \n",
    "        #ships\n",
    "        self.ships = ships\n",
    "        \n",
    "        # board size\n",
    "        self.grid_size = grid_size \n",
    "        # cell state encoding (empty, hit, miss)\n",
    "        self.cell = {'E': 0, 'X': 1, 'O': -1} \n",
    "        # boards, actions, rewards\n",
    "        self.board = self.cell['E']*np.ones((self.grid_size, self.grid_size), dtype='int')\n",
    "        # enemy_board must be encoded with 0: empy and 1: ship cell\n",
    "        self.is_enemy_set = False\n",
    "        self.enemy_board = enemy_board\n",
    "        self.ship_locs = ship_locs\n",
    "        if self.enemy_board is None:\n",
    "            self.enemy_board = 0*np.ones((self.grid_size, self.grid_size), dtype='int')\n",
    "            for ship in self.ships:\n",
    "                self.ship_locs[ship] = []\n",
    "                self.enemy_board, self.ship_locs = set_ship(ship, self.ships, self.enemy_board, self.ship_locs)\n",
    "            self.is_enemy_set = True\n",
    "        # reward discount\n",
    "        self.rdisc = 0\n",
    "        self.legal_actions = [] # legal (empty) cells available for moves\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                self.legal_actions.append((i,j))# this gets updated as an action is performed\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # In our case the action space is discrete: index of action\n",
    "        self.action_space = spaces.Discrete(self.grid_size * self.grid_size)\n",
    "        # The observation will be the state or configuration of the board\n",
    "        self.observation_space = spaces.Box(low=-1, high=1,shape=(self.grid_size, self.grid_size), \n",
    "                                            dtype=np.int)\n",
    "\n",
    "    # action will be an index in action_space if from epsilon-greedy\n",
    "    # or from model prediction\n",
    "    def step(self, action):\n",
    "                        \n",
    "        # board situation before the action\n",
    "        state = self.board.copy()        \n",
    "        empty_cnts_pre, hit_cnts_pre, miss_cnts_pre = self.board_config(state)\n",
    "        \n",
    "        # action coordinates generated or predicted by the agent in the action_space\n",
    "        i, j = np.unravel_index(action, (self.grid_size,self.grid_size))\n",
    "        \n",
    "        #print('action', action, 'coords', i, j)\n",
    "        #print('legal_actions', self.legal_actions)\n",
    "        \n",
    "        # lose 1 point for any action\n",
    "        reward = -1\n",
    "        # assign a penalty for each illegal action used instead of a legal one\n",
    "        if (i,j) not in self.legal_actions:\n",
    "            reward -= 2*self.grid_size\n",
    "            action_idx = np.random.randint(0,len(self.legal_actions))\n",
    "            \n",
    "            i,j = self.legal_actions[action_idx]                \n",
    "            action = np.ravel_multi_index((i,j), (self.grid_size,self.grid_size))\n",
    "        \n",
    "        # set new state after performing action (scoring board is updated)\n",
    "        self.set_state((i,j))\n",
    "        # update legal actions and action_space\n",
    "        self.set_legal_actions((i,j))\n",
    "\n",
    "        # new state on scoring board - this includes last action\n",
    "        next_state = self.board\n",
    "               \n",
    "        # board situation after action\n",
    "        empty_cnts_post, hit_cnts_post, miss_cnts_post = self.board_config(next_state)\n",
    "\n",
    "        # game completed?\n",
    "        done = bool(hit_cnts_post == sum(self.ships.values()))\n",
    "                    \n",
    "        # reward for a hit\n",
    "        if hit_cnts_post-hit_cnts_pre==1: \n",
    "            # Update hit counts and use it to reward\n",
    "            r_discount = 1#0.5**self.rdisc\n",
    "            rp = (self.grid_size*self.grid_size if done else self.grid_size)\n",
    "            reward += rp*r_discount\n",
    "            #print('HIT!!!')\n",
    "            \n",
    "        #if done:\n",
    "        #    print('done')\n",
    "            \n",
    "        # we discount the reward for a subsequent hit the longer it takes to score it\n",
    "        # after a hit, zero the discount \n",
    "        # don't start discounting though, if first hit hasn't happened yet\n",
    "        #if hit_cnts_post-hit_cnts_pre==1 or hit_cnts_pre==0:\n",
    "        #    self.rdisc = 0\n",
    "        #else:\n",
    "        #    self.rdisc += 1\n",
    "                    \n",
    "        reward = float(reward)\n",
    "            \n",
    "        #print('reward:', reward)\n",
    "        # store the current value of the portfolio here\n",
    "        info = {}\n",
    "\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        \"\"\"\n",
    "        Important: the observation must be a numpy array\n",
    "        :return: (np.array) \n",
    "        \"\"\"\n",
    "        \n",
    "        self.board = self.cell['E']*np.ones((self.grid_size, self.grid_size), dtype='int')\n",
    "        \n",
    "        self.legal_actions = [] # legal (empty) cells available for moves\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                self.legal_actions.append((i,j))# this gets updated as an action is performed\n",
    "               \n",
    "        # generate a random board again if it was set randomly before\n",
    "        if self.is_enemy_set:\n",
    "            self.enemy_board = 0*np.ones((self.grid_size, self.grid_size), dtype='int')\n",
    "            self.ship_locs = {}\n",
    "            for ship in self.ships:\n",
    "                self.ship_locs[ship] = []\n",
    "                self.enemy_board, self.ship_locs = set_ship(ship, self.ships, self.enemy_board, self.ship_locs)\n",
    "\n",
    "        self.rdisc = 0\n",
    "\n",
    "        return self.board\n",
    "    \n",
    "    # Render the environment to the screen\n",
    "    # board (i,j)\n",
    "    ## ------------>j\n",
    "    ## | (0,0) | (0,1) | (0,2) | |\n",
    "    ## | (1,0) | (1,1) | (1,2) | |\n",
    "    ##                           v i\n",
    "    def render(self, mode='human'):\n",
    "        for i in range(self.grid_size):\n",
    "            print(\"-\"*(4*self.grid_size+2))\n",
    "            for j in range(self.grid_size):\n",
    "                current_state_value = self.board[i,j]\n",
    "                current_state = list(self.cell.keys())[list(self.cell.values()).index(current_state_value)]\n",
    "                current_state = (current_state if current_state!='E' else ' ')\n",
    "                print(\" | \", end=\"\")\n",
    "                print(current_state, end='')\n",
    "            print(' |')\n",
    "        print(\"-\"*(4*self.grid_size+2))\n",
    "        \n",
    "    ####### HELPER FUNCTIONS ###########\n",
    "    \n",
    "    def board_config(self, state):\n",
    "        uni_states, uni_cnts = np.unique(state.ravel(), return_counts=True)\n",
    "        empty_cnts = uni_cnts[uni_states==self.cell['E']]\n",
    "        hit_cnts = uni_cnts[uni_states==self.cell['X']]\n",
    "        miss_cnts = uni_cnts[uni_states==self.cell['O']]\n",
    "        if len(empty_cnts)==0:\n",
    "            empty_cnts = 0\n",
    "        else:\n",
    "            empty_cnts = empty_cnts[0]\n",
    "        if len(hit_cnts)==0:\n",
    "            hit_cnts = 0\n",
    "        else:\n",
    "            hit_cnts = hit_cnts[0]\n",
    "        if len(miss_cnts)==0:\n",
    "            miss_cnts = 0\n",
    "        else:\n",
    "            miss_cnts = miss_cnts[0]\n",
    "        \n",
    "        return empty_cnts, hit_cnts, miss_cnts\n",
    "\n",
    "    # set board configuration and state value after player action\n",
    "    def set_state(self, action):\n",
    "        i , j = action\n",
    "        if self.enemy_board[i,j]==1:\n",
    "            self.board[i,j]=self.cell['X']\n",
    "        else:\n",
    "            self.board[i,j]=self.cell['O']\n",
    "\n",
    "    # set legal actions (empty board locations)\n",
    "    def set_legal_actions(self, action):\n",
    "        if action in self.legal_actions:\n",
    "            self.legal_actions.remove(action)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff249f2",
   "metadata": {},
   "source": [
    "## Validate environment with either random defined ship on 5x5 board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09618b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enes1\\AppData\\Local\\Temp/ipykernel_18684/2322792659.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n",
      "C:\\Users\\enes1\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:190: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ships\n",
    "ships = {}\n",
    "ships['cruiser'] = 3\n",
    "\n",
    "grid_size = 5\n",
    "# for pre-determined board\n",
    "# enemy_board = 0*np.ones((grid_size, grid_size), dtype='int')\n",
    "# enemy_board[0,1] = 1\n",
    "# enemy_board[1,1] = 1\n",
    "# enemy_board[2,1] = 1\n",
    "# ship_locs = {}\n",
    "# ship_locs['cruiser'] = [(0,1),(1,1),(2,1)]\n",
    "# env = BattleshipEnv(enemy_board=enemy_board, ship_locs=ship_locs, grid_size=grid_size, ships=ships)\n",
    "# for random board\n",
    "env = BattleshipEnv(enemy_board=None, ship_locs={}, grid_size=grid_size, ships=ships)\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3a1c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]),\n",
       " {'cruiser': [(0, 1), (0, 2), (0, 3)]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.enemy_board, env.ship_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d06fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enes1\\AppData\\Local\\Temp/ipykernel_18684/2322792659.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Action 1 row: 1 index: 1\n",
      "obs= [[ 0  0  0  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 2 row: 1 index: 1\n",
      "obs= [[ 0  0  0  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0  0  0]] reward= -6.0 done= False\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | X |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 3 row: 3 index: 3\n",
      "obs= [[ 0  0  0  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0  0  0]] reward= -11.0 done= False\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   |   |   | X |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 4 row: 3 index: 1\n",
      "obs= [[ 0  0  0  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0 -1  0  1  0]\n",
      " [ 0  0  0  0  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   | X |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 5 row: 0 index: 3\n",
      "obs= [[ 0  0  0 -1  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0 -1  0  1  0]\n",
      " [ 0  0  0  0  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   | X |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 6 row: 3 index: 2\n",
      "obs= [[ 0  0  0 -1  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0  0  0  0  0]] reward= 4.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 7 row: 4 index: 4\n",
      "obs= [[ 0  0  0 -1  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0  0  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   |   |   |   | O |\n",
      "----------------------\n",
      "Action 8 row: 4 index: 1\n",
      "obs= [[ 0  0  0 -1  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 9 row: 2 index: 4\n",
      "obs= [[ 0  0  0 -1  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 10 row: 0 index: 4\n",
      "obs= [[ 0  0  0 -1 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 11 row: 3 index: 2\n",
      "obs= [[-1  0  0 -1 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O |   |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 12 row: 1 index: 1\n",
      "obs= [[-1  0  0 -1 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O |   |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 13 row: 1 index: 4\n",
      "obs= [[-1  0  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O |   |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 14 row: 0 index: 1\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 15 row: 3 index: 3\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [ 0 -1  0  0 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      "Action 16 row: 3 index: 1\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [-1 -1  0  0 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   |   | O |\n",
      "----------------------\n",
      "Action 17 row: 4 index: 3\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 18 row: 0 index: 0\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0  0 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   |   | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 19 row: 0 index: 3\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 20 row: 0 index: 3\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 0 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " |   | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 21 row: 3 index: 0\n",
      "obs= [[-1 -1  0 -1 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 22 row: 0 index: 0\n",
      "obs= [[-1 -1 -1 -1 -1]\n",
      " [-1 -1  0 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 23 row: 3 index: 2\n",
      "obs= [[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1  1  1  0]\n",
      " [-1 -1  0 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | X | X |   |\n",
      "----------------------\n",
      " | O | O |   | O | O |\n",
      "----------------------\n",
      "Action 24 row: 0 index: 0\n",
      "obs= [[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1  1  1  0]\n",
      " [-1 -1 -1 -1 -1]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | X | X |   |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      "Action 25 row: 3 index: 3\n",
      "obs= [[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1  1  1  1]\n",
      " [-1 -1 -1 -1 -1]] reward= 14.0 done= True\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O | O | X | X | X |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      "Goal reached! reward= 14.0\n",
      "Episode 1\n",
      "Action 1 row: 0 index: 2\n",
      "obs= [[0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]] reward= 4.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      "Action 2 row: 4 index: 2\n",
      "obs= [[ 0  0  1  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1  0  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O |   |   |\n",
      "----------------------\n",
      "Action 3 row: 1 index: 1\n",
      "obs= [[ 0  0  1  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1  0  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O |   |   |\n",
      "----------------------\n",
      "Action 4 row: 2 index: 2\n",
      "obs= [[ 0  0  1  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1  0  0]] reward= 4.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O |   |   |\n",
      "----------------------\n",
      "Action 5 row: 4 index: 3\n",
      "obs= [[ 0  0  1  0  0]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 6 row: 0 index: 4\n",
      "obs= [[ 0  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 7 row: 2 index: 4\n",
      "obs= [[ 0  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0 -1]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 8 row: 3 index: 3\n",
      "obs= [[ 0  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0 -1]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 9 row: 2 index: 4\n",
      "obs= [[-1  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0 -1]\n",
      " [ 0  0  0 -1  0]\n",
      " [ 0  0 -1 -1  0]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   |   |   | O |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 10 row: 4 index: 3\n",
      "obs= [[-1  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0  0  1  0 -1]\n",
      " [ 0 -1  0 -1  0]\n",
      " [ 0  0 -1 -1  0]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   | O |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 11 row: 2 index: 1\n",
      "obs= [[-1  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1  0 -1]\n",
      " [ 0 -1  0 -1  0]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   | O |   |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 12 row: 3 index: 4\n",
      "obs= [[-1  0  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1  0 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O |   | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 13 row: 3 index: 3\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1  0 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0  0 -1 -1  0]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 14 row: 2 index: 3\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1 -1 -1]\n",
      " [ 0 -1  0 -1 -1]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X | O | O |\n",
      "----------------------\n",
      " |   | O |   | O | O |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 15 row: 2 index: 2\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1]\n",
      " [ 0  0 -1 -1  0]] reward= -11.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X | O | O |\n",
      "----------------------\n",
      " |   | O | O | O | O |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 16 row: 3 index: 0\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 0  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " |   |   | O | O |   |\n",
      "----------------------\n",
      "Action 17 row: 4 index: 0\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [ 0 -1  1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " |   | O | X | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O |   | O | O |   |\n",
      "----------------------\n",
      "Action 18 row: 2 index: 0\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  0  0  0]\n",
      " [-1 -1  1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]] reward= -1.0 done= False\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O |   |   |   |\n",
      "----------------------\n",
      " | O | O | X | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O |   | O | O |   |\n",
      "----------------------\n",
      "Action 19 row: 2 index: 1\n",
      "obs= [[-1 -1  1  0 -1]\n",
      " [ 0 -1  1  0  0]\n",
      " [-1 -1  1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]] reward= 14.0 done= True\n",
      "----------------------\n",
      " | O | O | X |   | O |\n",
      "----------------------\n",
      " |   | O | X |   |   |\n",
      "----------------------\n",
      " | O | O | X | O | O |\n",
      "----------------------\n",
      " | O | O | O | O | O |\n",
      "----------------------\n",
      " | O |   | O | O |   |\n",
      "----------------------\n",
      "Goal reached! reward= 14.0\n"
     ]
    }
   ],
   "source": [
    "# Test environment\n",
    "# ships\n",
    "ships = {}\n",
    "ships['cruiser'] = 3\n",
    "\n",
    "grid_size=5\n",
    "env = BattleshipEnv(enemy_board=None, ship_locs={}, grid_size=grid_size, ships=ships)\n",
    "\n",
    "for ep in range(2):\n",
    "    print('Episode', ep)\n",
    "    obs = env.reset()\n",
    "    #env.render()\n",
    "    #print(env.enemy_board)\n",
    "    done = False\n",
    "    t = 0\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        i, j = np.unravel_index(action, (grid_size,grid_size))    \n",
    "        print(\"Action {}\".format(t + 1), \"row:\", i, \"index:\", j)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "        env.render()\n",
    "        t += 1\n",
    "        if done:\n",
    "            print(\"Goal reached!\", \"reward=\", reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6649d5",
   "metadata": {},
   "source": [
    "## Callback and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2b52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, episode_interval: int, log_dir: str, verbose=1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.episode_interval = episode_interval\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model.pkl')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            # Evaluate policy training performance\n",
    "            x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                # NOTE: when done is True, timesteps are counted and reported to the log_dir\n",
    "                mean_reward = np.mean(y[-self.episode_interval:]) # mean reward over previous episode_interval episodes\n",
    "                mean_moves = np.mean(np.diff(x[-self.episode_interval:])) # mean moves over previous 100 episodes\n",
    "                if self.verbose > 0:\n",
    "                    print(x[-1], 'timesteps') # closest to step_interval step number\n",
    "                    print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f} - Last mean moves per episode: {:.2f}\".format(self.best_mean_reward, \n",
    "                                                                                                   mean_reward, mean_moves))\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Saving new best model\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945ee372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, 'valid')\n",
    "\n",
    "\n",
    "def plot_results(log_folder, window = 100, title='Learning Curve'):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    \n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    y = moving_average(y, window=window)\n",
    "    y_moves = moving_average(np.diff(x), window = window) \n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y):]\n",
    "    x_moves = x[len(x) - len(y_moves):]\n",
    "\n",
    "    title = 'Smoothed Learning Curve of Rewards (every ' + str(window) +' steps)'\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    title = 'Smoothed Learning Curve of Moves (every ' + str(window) +' steps)'\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x_moves, y_moves)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Moves')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9492633",
   "metadata": {},
   "source": [
    "## Making the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f2cd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
    "    :param _locals: (dict)\n",
    "    :param _globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    # Print stats every step_interval calls\n",
    "    if (n_steps + 1) % step_interval == 0:\n",
    "        # Evaluate policy training performance\n",
    "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "        if len(x) > 0:\n",
    "            # NOTE: when done is True, timesteps are counted and reported to the log_dir\n",
    "            mean_reward = np.mean(y[-episode_interval:]) # mean reward over previous episode_interval episodes\n",
    "            mean_moves = np.mean(np.diff(x[-episode_interval:])) # mean moves over previous episode_interval episodes\n",
    "            print(x[-1], 'timesteps') # closest to step_interval step number\n",
    "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f} - Last mean moves per episode: {:.2f}\".format(best_mean_reward, \n",
    "                                                                                           mean_reward, mean_moves))\n",
    "\n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                print(\"Saving new best model\")\n",
    "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    n_steps += 1\n",
    "    # Returning False will stop training early\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ba9bc",
   "metadata": {},
   "source": [
    "## Trainig on 5x5 board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35bf3df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enes1\\AppData\\Local\\Temp/ipykernel_18684/2322792659.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9986 timesteps\n",
      "Best mean reward: -inf - Last mean reward per episode: -58.97 - Last mean moves per episode: 19.21\n",
      "Saving new best model\n",
      "19984 timesteps\n",
      "Best mean reward: -58.97 - Last mean reward per episode: -54.80 - Last mean moves per episode: 18.68\n",
      "Saving new best model\n",
      "29994 timesteps\n",
      "Best mean reward: -54.80 - Last mean reward per episode: -52.29 - Last mean moves per episode: 18.38\n",
      "Saving new best model\n",
      "40000 timesteps\n",
      "Best mean reward: -52.29 - Last mean reward per episode: -49.28 - Last mean moves per episode: 17.95\n",
      "Saving new best model\n",
      "49992 timesteps\n",
      "Best mean reward: -49.28 - Last mean reward per episode: -47.56 - Last mean moves per episode: 17.64\n",
      "Saving new best model\n",
      "59990 timesteps\n",
      "Best mean reward: -47.56 - Last mean reward per episode: -45.77 - Last mean moves per episode: 17.37\n",
      "Saving new best model\n",
      "69999 timesteps\n",
      "Best mean reward: -45.77 - Last mean reward per episode: -43.68 - Last mean moves per episode: 17.02\n",
      "Saving new best model\n",
      "79992 timesteps\n",
      "Best mean reward: -43.68 - Last mean reward per episode: -42.69 - Last mean moves per episode: 16.81\n",
      "Saving new best model\n",
      "89993 timesteps\n",
      "Best mean reward: -42.69 - Last mean reward per episode: -41.72 - Last mean moves per episode: 16.60\n",
      "Saving new best model\n",
      "99994 timesteps\n",
      "Best mean reward: -41.72 - Last mean reward per episode: -40.90 - Last mean moves per episode: 16.42\n",
      "Saving new best model\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "# ships -- keep only one kind for 5x5 grid\n",
    "ships = {}\n",
    "ships['cruiser'] = 3\n",
    "\n",
    "grid_size = 5\n",
    "num_timesteps = 100000 # this is number of moves and not number of episodes\n",
    "\n",
    "best_mean_reward, n_steps, step_interval, episode_interval = -np.inf, 0, 10000, 10000\n",
    "\n",
    "# Instantiate the env\n",
    "env = BattleshipEnv(enemy_board=None, ship_locs={}, grid_size=grid_size, ships=ships)\n",
    "\n",
    "# wrap it\n",
    "log_dir = \"./gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "env = Monitor(env, filename=log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Train the agent - Note: best model is not save in Callback function for PPO2; save manually\n",
    "model = A2C('MlpPolicy', env, verbose=0).learn(total_timesteps=num_timesteps, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c598ab82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecef02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = A2C.load('./gym/best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276a0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode no. 0 # moves: 5\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   | O | O |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | X | X | X |   |\n",
      "----------------------\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   |   |   |   |   |\n",
      "----------------------\n",
      " |   | S | S | S |   |\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "ships = {}\n",
    "ships['cruiser'] = 3\n",
    "\n",
    "grid_size=5\n",
    "enemy_board = 0*np.ones((grid_size, grid_size), dtype='int')\n",
    "env = BattleshipEnv(enemy_board=None, ship_locs={}, grid_size=grid_size, ships=ships)\n",
    "# give me time to setup recording\n",
    "time.sleep(5)\n",
    "for ep in range(1):\n",
    "    obs = env.reset()\n",
    "    ## 2 empty boards\n",
    "    done = False\n",
    "    nmoves = 0\n",
    "    print('episode no.', ep, '# moves:', nmoves)\n",
    "    env.render()\n",
    "    env.render()\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)        \n",
    "    while not done:\n",
    "        action, obs = model_best.predict(obs, deterministic=True)\n",
    "        obs, _, done , _ = env.step(action)\n",
    "        nmoves += 1\n",
    "        print('episode no.', ep, '# moves:', nmoves)\n",
    "        env.render()\n",
    "        board_rendering(grid_size, env.enemy_board)\n",
    "        time.sleep(np.random.uniform(1,3))\n",
    "        clear_output(wait=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab5773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
